{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled32.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVuF5oD_H3Zk"
      },
      "source": [
        "import tensorflow as tf \n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "tfds.disable_progress_bar()\n",
        "from tqdm import tqdm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b840zNxNYrh",
        "outputId": "9ce0858d-1133-410b-bd64-7c5c204ae88a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "module_selection = (\"mobilenet_v2\", 224, 1280) #@param [\"(\\\"mobilenet_v2\\\", 224, 1280)\", \"(\\\"inception_v3\\\", 299, 2048)\"] {type:\"raw\", allow-input: true}\n",
        "handle_base, pixels, FV_SIZE = module_selection\n",
        "MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "print(\"Using {} with input size {} and output dimension {}\".format(MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4 with input size (224, 224) and output dimension 1280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV6hLMDuOwB_",
        "outputId": "2d04fd15-4d24-4990-ce68-d7d8b7286990",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "splits = tfds.Split.ALL.subsplit(weighted=(80, 10, 10))\n",
        "\n",
        "splits, info = tfds.load('cats_vs_dogs',split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],with_info=True,as_supervised=True,)\n",
        "\n",
        "(train_examples, validation_examples, test_examples) = splits\n",
        "\n",
        "num_examples = info.splits['train'].num_examples\n",
        "num_classes = info.features['label'].num_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset cats_vs_dogs/4.0.0 (download: 786.68 MiB, generated: Unknown size, total: 786.68 MiB) to /root/tensorflow_datasets/cats_vs_dogs/4.0.0...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "WARNING:absl:1738 images were corrupted and were skipped\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shuffling and writing examples to /root/tensorflow_datasets/cats_vs_dogs/4.0.0.incompleteWDN6ZO/cats_vs_dogs-train.tfrecord\n",
            "\u001b[1mDataset cats_vs_dogs downloaded and prepared to /root/tensorflow_datasets/cats_vs_dogs/4.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xonw-sehSgmZ"
      },
      "source": [
        "def format_image(image,label):\n",
        "  image = tf.image.resize(image,IMAGE_SIZE)\n",
        "  return image,label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4wNkVkqUxMS"
      },
      "source": [
        "BATCH_SIZE = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7zD-cWLU1kI"
      },
      "source": [
        "train_batches= train_examples.shuffle(num_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3kcQLBxYNX3"
      },
      "source": [
        "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "test_batches = test_examples.map(format_image).batch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKu34S6hYRrw",
        "outputId": "dc795c0d-b5af-4c11-eda8-306c4db1e07c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for image_batch,label_batch in train_batches.take(1):\n",
        "  pass\n",
        "image_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([32, 224, 224, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1m8RGddZJdd"
      },
      "source": [
        "do_fine_tuning = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzwjm0rucosV"
      },
      "source": [
        "feature_extractor = hub.KerasLayer(MODULE_HANDLE,input_shape = IMAGE_SIZE+(3,),output_shape=[FV_SIZE],trainable=do_fine_tuning)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSpBxY46dRpc",
        "outputId": "f6e6ff0f-e74b-4eb6-dd54-23074cde3bd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(\"building model with \",MODULE_HANDLE)\n",
        "model = tf.keras.Sequential([\n",
        "        feature_extractor,\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "building model with  https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer (KerasLayer)     (None, 1280)              2257984   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 2562      \n",
            "=================================================================\n",
            "Total params: 2,260,546\n",
            "Trainable params: 2,562\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl60oQpHfu3v"
      },
      "source": [
        "NUM_LAYERS = 10\n",
        "if do_fine_tuning:\n",
        "  feature_extractor.trainable = True\n",
        "  for layers in model.layers[-NUM_LAYERS:]:\n",
        "    layer.trainable = True\n",
        "else :\n",
        "  feature_extractor.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OAztV4_gfoN"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',optimizer = 'adam' ,metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeX6RUZqg0lf",
        "outputId": "cce27dae-cf86-413a-fff7-ef341f453be4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "EPOCHS= 5\n",
        "hist = model.fit(train_batches,\n",
        "                 epochs=EPOCHS,\n",
        "                 validation_data=validation_batches)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "582/582 [==============================] - 651s 1s/step - loss: 0.5807 - accuracy: 0.6962 - val_loss: 0.5359 - val_accuracy: 0.7223\n",
            "Epoch 2/5\n",
            "582/582 [==============================] - 651s 1s/step - loss: 0.5152 - accuracy: 0.7458 - val_loss: 0.5079 - val_accuracy: 0.7532\n",
            "Epoch 3/5\n",
            "582/582 [==============================] - 647s 1s/step - loss: 0.5026 - accuracy: 0.7542 - val_loss: 0.5028 - val_accuracy: 0.7575\n",
            "Epoch 4/5\n",
            "582/582 [==============================] - 648s 1s/step - loss: 0.4883 - accuracy: 0.7618 - val_loss: 0.4929 - val_accuracy: 0.7528\n",
            "Epoch 5/5\n",
            "582/582 [==============================] - 646s 1s/step - loss: 0.4789 - accuracy: 0.7696 - val_loss: 0.4882 - val_accuracy: 0.7623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjzg1kn8hKpQ",
        "outputId": "ca69d600-0608-435b-8e67-c7050d87d7cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "CATS_VS_DOGS_SAVED_MODEL =\"exp_saved_model\"\n",
        "tf.saved_model.save(model,CATS_VS_DOGS_SAVED_MODEL)\n",
        "loaded = tf.saved_model.load(CATS_VS_DOGS_SAVED_MODEL)\n",
        "print(list(loaded.signatures.keys()))\n",
        "infer = loaded.signatures['serving_default']\n",
        "print(infer.structured_input_signature)\n",
        "print(infer.structured_outputs)\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(CATS_VS_DOGS_SAVED_MODEL)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: exp_saved_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: exp_saved_model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['serving_default']\n",
            "((), {'keras_layer_input': TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_layer_input')})\n",
            "{'dense': TensorSpec(shape=(None, 2), dtype=tf.float32, name='dense')}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5O1CJBA4vuF"
      },
      "source": [
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "def representative_data_gen():\n",
        "    for input_value, _ in test_batches.take(100):\n",
        "        yield [input_value]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "\n",
        "\n",
        "tf_lite_model = converter.convert()\n",
        "tflite_model_file = 'converted_model.tflite'\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf_i0LNfK_6P",
        "outputId": "eb0e00b4-757b-4079-dc6b-dfadc8433fc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions = []\n",
        "test_labels,test_imgs = [],[]\n",
        "for img,label in tqdm(test_batches.take(10)):\n",
        "  interpreter.set_tensor(input_index,img)\n",
        "  interpreter.invoke()\n",
        "  predictions.append(interpreter.get_tensor(output_index))\n",
        "  test_labels.append(label.numpy()[0])\n",
        "  test_imgs.append(img)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10it [00:11,  1.12s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V2IhexJL94G"
      },
      "source": [
        "\n",
        "class_names = ['cat', 'dog']\n",
        "\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    \n",
        "    img = np.squeeze(img)\n",
        "\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "    \n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "    \n",
        "    if predicted_label == true_label:\n",
        "        color = 'green'\n",
        "    else:\n",
        "        color = 'red'\n",
        "    \n",
        "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                         100*np.max(predictions_array),\n",
        "                                         class_names[true_label]), color=color)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twaVKx1xOI1S",
        "cellView": "form",
        "outputId": "82c832be-5f2a-4e99-cb4f-f7142c171fb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "index = 3 #@param {type:\"slider\", min:0, max:9, step:1}\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(index, predictions, test_labels, test_imgs)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GacLN0OO0BO"
      },
      "source": [
        "labels = ['cat', 'dog']\n",
        "\n",
        "with open('labels.txt', 'w') as f:\n",
        "    f.write('\\n'.join(labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_uBRR1eRP-e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}